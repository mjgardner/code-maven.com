=title Introduction to Python unittest
=timestamp 2017-10-11T08:30:01
=indexes unittest
=status show
=books python
=author szabgab
=archive 1
=comments_disqus_enable 0

=abstract start

Using <a href="/doctest-in-python">doctest</a> is nice, but it is not very good for large test suites.

The <a href="https://docs.python.org/3/library/unittest.html">unittest</a> module is another standard module
that provides a much more powerful way to write tests and despite its name it can be used to write integration
and acceptance tests just as well as unittests.

=abstract end

<h2>Simple use case of unittest</h2>

From the <a href="/doctest-in-python">previous article</a> you might be familiar with
the extremely complex Python module that we wanted to test:

<include file="examples/python/dt/mymod_1.py">

It has a single function called <hl>is_anagram</hl> that checks if two strings passed to it are anagrams of each other.

<h2>First tests</h2>

<include file="examples/python/dt/test_mymod_1.py">

<h3>The infrastructure</h3>

Unittests usually go into a separate file which is usually called test_*.
This naming is not required for the basic usage, but later we'll see that
the <hl>unittest</hl> module can "autodiscover" the test file and then having
the files named test_* is one way to let it do its job.

Besides, it makes it easier to the humans looking at your code to set the
application code and the test code aside.

Inside the code we need to load the <hl>unittest</hl> module.
We need to create a class that inherits from <hl>unittest.TestCase</hl>.
Naming the class <hl>TestSomething</hl> is not required but that's another
nice convention.

Lastly we need to create methods that start with <hl>test_*</hl>.

We might also need some helper methods that won't be called test_*.

Inside the test-methods we use the <hl>assertTrue</hl> and <hl>assertFalse</hl>
methods inherited from <hl>unittest.TestCase</hl> to assert whether the function
returns <hl>True</hl> or <hl>False</hl> as expected from it.

As opposed to the <hl>assert</hl> statement of Python, these <hl>assert...</hl>
methods will not raise exceptions and thus even if some of them fail, the rest
will still be executed. That way we can get the overall picture of our test
and won't stop on the first failure.

The last piece of infrastructure is the conditional running of the <hl>main</hl>
function. It is only used as convenience to make it easy to run the tests.

<code>
if __name__ == '__main__':
    unittest.main()
</code>

<h3>The actual tests</h3>

So far we talked only about the infrastructure of the tests.
In order to actually execute out code, the AUT (Application Under Test)
we need to load it as we would in the "real world". e.g. by <hl>from mymod_1 import is_anagram</hl>
and then inside the <hl>assert..</hl> methods we just call the function we would like to
test. For example: <hl>is_anagram("abc", "acb")</hl>

<h3>Running the tests</h3>

As we included the condition running of the tests in the test-file itself we can run the test-file
directly: <hl>python test_mymod_1.py</hl>

<code>
$ python test_mymod_1.py

.
----------------------------------------------------------------------
Ran 1 test in 0.000s

OK
</code>

The single dot <hl>.</hl> and the number 1 indicate that we had one test_* method in our file.
It does not count the individual assertions.

The <hl>OK</hl> tells us that every assertion in every test_* method passed.

<h2>Dealing with failures</h2>

As in the previous article, here too we would like to see what happens if a test fails.
In our case someone was not satisfied with single-word anagrams and expected to be
able to have spaces in at least one of the "words". We test this by adding 
another test_* method to our file:

<include file="examples/python/dt/test_mymod_2.py">

Running this file we get the following output:

<code>
$ python test_mymod_2.py

.F
======================================================================
FAIL: test_multiword_anagram (__main__.TestAnagram)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "test_mymod_2.py", line 12, in test_multiword_anagram
    self.assertTrue( is_anagram("anagram", "nag a ram") )
AssertionError: False is not true

----------------------------------------------------------------------
Ran 2 tests in 0.000s

FAILED (failures=1)
</code>

Here we can see a single dot <hl>.</hl> indicating a single test_* method that had
all its assertions passed and a single <hl>F</hl> that indicates the test_* method
that failed at least one of its assertions.

The <hl>FAIL</hl> part indicates the test_* method that failed.

The <hl>Traceback</hl> provides detailed information about the actual failure.

<h2>Running individual test methods</h2>

If you encounter a failure in one of the tests in your test suite, you will usually want
to fix the problem that generated that test-failure.
For that you'll want to run the tests repeatedly, but when focusing on one part of the code
and on a single test_* method, it might be a waste of time to keep running the whole
test-suite. Luckily <hl>unittest</hl> allows us to run the test methods individually.
for that we need to pass the name of the test-class and the name of the test-method on
the command line: <hl>python test_mymod_2.py TestAnagram.test_anagram</hl>.

The output for the successful test method looks like this:

<code>
$ python test_mymod_2.py TestAnagram.test_anagram

.
----------------------------------------------------------------------
Ran 1 test in 0.000s

OK
</code>

Here you can see that there is only a single dot <hl>.</hl> indicating that only a single
test-method was executed.


The output of the failing test method looks like this:

<code>
$ python test_mymod_2.py TestAnagram.test_multiword_anagram

F
======================================================================
FAIL: test_multiword_anagram (__main__.TestAnagram)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "test_mymod_2.py", line 12, in test_multiword_anagram
    self.assertTrue( is_anagram("anagram", "nag a ram") )
AssertionError: False is not true

----------------------------------------------------------------------
Ran 1 test in 0.000s

FAILED (failures=1)
</code>

Here you can see a single <hl>F</hl> and no dot <hl>.</hl> indicating that only a single failing
test-method was executed.

<h2>Running tests without the conditional running</h2>

The last part of the test-files are actually not really necessary.
We could eliminate the

<code>
if __name__ == '__main__':
    unittest.main()
</code>

and have the following:

<include file="examples/python/dt/test_mymod_3.py">

Then we need to load the <hl>unittest</hl> module on the command line as well.
Like this:

<code>
python -m unittest test_mymod_3
</code>

The result would be the same.

We can also run the individual test-methods by providing the exact, dot-separated path
on the command line: (test-file.test-class.test-method)

<code>
python -m unittest test_mymod_3.TestAnagram.test_multiword_anagram
</code>


<h2>Test discovery</h2>

Finally, as we named our test-files test_* we can also make use if the <hl>autodiscovery</hl> feature
of the <hl>unittest</hl> module. We can run <hl>python -m unittest discover</hl> and let it find
all the tests files.

In our case this will be a bit funny as we have 3 files in our directory with (almost) the same tests.
That's because of the examples above. However this can also show that the <hl>discover</hl> feature
runs all the 3 files.

The report actually does not indicate that there were 3 files only, that we have a total of 5 test-methods.
3 dots <hl>.</hl> indicating 3 methods that were successful. 2 <hl>F</hl> characters indicating that
two of the methods failed. (Yes, I know, they are copies of each other.)


<code>
$ python -m unittest discover

..F.F
======================================================================
FAIL: test_multiword_anagram (test_mymod_2.TestAnagram)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ".../examples/python/dt/test_mymod_2.py", line 12, in test_multiword_anagram
    self.assertTrue( is_anagram("anagram", "nag a ram") )
AssertionError: False is not true

======================================================================
FAIL: test_multiword_anagram (test_mymod_3.TestAnagram)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ".../examples/python/dt/test_mymod_3.py", line 12, in test_multiword_anagram
    self.assertTrue( is_anagram("anagram", "nag a ram") )
AssertionError: False is not true

----------------------------------------------------------------------
Ran 5 tests in 0.001s

FAILED (failures=2)
</code>

In Python 3 you don't even add the <hl>discover</hl> to the end. This will already start the discovery process:

<code>
$ python -m unittest 
</code>


<h2>Conclusion</h2>

In any case you can now write tests using the <hl>unittest</hl> module.
You can run them and if something fails you can focus on the failing test
instead of running the whole suite again and again.

BTW as you can see the test-methods are the smallest units the <hl>unittest</hl>
module can operate on, so it is probably a good idea to keep them very short
and focused on specific features.

<h2>Comments</h2>

That was awesome explanation about uninttest.
Would like to know one thing, is there a possibility of collecting all failed test cases & rerunning ?


